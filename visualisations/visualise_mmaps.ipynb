{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cc5d7c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"../src\")\n",
    "import pickle\n",
    "import scipy\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from collections import defaultdict\n",
    "from data import preprocess_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8a36c2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def store_mmap(dataset_name, model_name):\n",
    "    dataset, idxs = preprocess_dataset(dataset_name)\n",
    "    train_prob = defaultdict(list)\n",
    "    test_prob = defaultdict(list)\n",
    "    memorised = defaultdict(list)\n",
    "\n",
    "    data = pickle.load(open(\n",
    "        f\"../checkpoints/{dataset_name}/mmap_{dataset_name}_{model_name}.pickle\", 'rb'))\n",
    "\n",
    "    for i in range(len(data) - 1):\n",
    "        train_idx, test_idx, train_logits, test_logits = data[i]\n",
    "        for x, y in zip(train_idx, train_logits):\n",
    "            memorised[x].append(dataset[\"train\"][x][\"labels\"] == np.argmax(y))\n",
    "        for x, y in zip(train_idx, train_logits):\n",
    "            train_prob[x].append(scipy.special.softmax(y)[dataset[\"train\"][x][\"labels\"]])\n",
    "        for x, y in zip(test_idx, test_logits):\n",
    "            test_prob[x].append(scipy.special.softmax(y)[dataset[\"train\"][x][\"labels\"]])\n",
    "\n",
    "    # post process into CM scores\n",
    "    x, y, hue = [], [], []\n",
    "    for k in train_prob:\n",
    "        if k in test_prob:\n",
    "            hue_label = None\n",
    "            for key in idxs:\n",
    "                if k in idxs[key]:\n",
    "                    hue_label = key\n",
    "            if hue_label is None:\n",
    "                hue_label = \"other\"\n",
    "\n",
    "            x.append(np.mean(train_prob[k]))\n",
    "            y.append(np.mean(test_prob[k]))\n",
    "            hue.append(hue_label)\n",
    "\n",
    "    cm = [max(0, round(x_ - y_, 1)) for y_, x_ in zip(y, x)]\n",
    "    # visualise full mem-map\n",
    "    sns.set_context(\"talk\")\n",
    "    ax = sns.jointplot(x=x, y=y, alpha=1, hue=cm, palette=\"Spectral\")\n",
    "    sns.lineplot(x=[0, 1], y=[0, 1], color=\"black\", linestyle='--')\n",
    "    han, lab = ax.ax_joint.get_legend_handles_labels()\n",
    "    ax.ax_joint.legend(han, lab, title=\"counterfactual\\nmemorisation\",\n",
    "                       frameon=False, fontsize=13, title_fontsize=13)\n",
    "    plt.xlim(0, 1)\n",
    "    plt.ylim(0, 1)\n",
    "    plt.xlabel(\"training memorisation\")\n",
    "    plt.ylabel(\"generalisation score\")\n",
    "    plt.show()\n",
    "\n",
    "    # visual mem map using the category labels\n",
    "    ax = sns.jointplot(x=x, y=y, hue=hue, palette=\"viridis\",\n",
    "                       joint_kws={'style': hue,\n",
    "                                  'alpha':[0.1 if label == \"other\" else 1 for label in hue]},\n",
    "                       marginal_kws={'common_norm':False})\n",
    "    sns.lineplot(x=[0, 1], y=[0, 1], color=\"black\", linestyle='--')\n",
    "    han, lab = ax.ax_joint.get_legend_handles_labels()\n",
    "    ax.ax_joint.legend(han, lab,\n",
    "                       frameon=False, fontsize=13, title_fontsize=13)\n",
    "    plt.xlim(0, 1)\n",
    "    plt.ylim(0, 1)\n",
    "    plt.xlabel(\"training memorisation\")\n",
    "    plt.ylabel(\"generalisation score\")\n",
    "    plt.show()\n",
    "\n",
    "    # Store generalisation scores to file\n",
    "    pickle.dump(\n",
    "        {k: np.mean(v) for k, v in test_prob.items()},\n",
    "        open(f\"../checkpoints/{dataset_name}/genscore_{dataset_name}_{model_name}.pickle\", 'wb')\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4daf3f69",
   "metadata": {},
   "outputs": [],
   "source": [
    "models = [\"EleutherAI_pythia-160m-deduped\", \"EleutherAI_gpt-neo-125m\", \"bert-base-cased\", \"facebook_opt-125m\"]\n",
    "datasets = [\"wic\", \"rte\", \"mrpc\", \"cola\", \"boolq\", \"sst2\", \"sst5\",\n",
    "            \"emotion\",  \"implicithate\", \"stormfront\", \"reuters\", \"trec\"]\n",
    "\n",
    "for model in models:\n",
    "    for dataset in datasets:\n",
    "        print(model, dataset)\n",
    "        store_mmap(dataset, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db78e929",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
